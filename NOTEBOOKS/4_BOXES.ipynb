{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6808a62-2b50-4321-9ca5-a49b528e38c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "os.chdir('C:/Users/Carlo/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbc0ac0-36c6-442d-bf0f-a2ff7fe07a0b",
   "metadata": {},
   "source": [
    "In this section, we'll see how to transform a 3D file so that it can be read by our Python program.\n",
    "\n",
    "Let’s begin.\n",
    "\n",
    "Our bounding boxes are the volumes where, when the hands enter, we can say the operator is working on a component X.\n",
    "\n",
    "To define these volumes, you can either:\n",
    "\n",
    "1-Manually write a .yml file specifying the coordinates of the nearest and farthest vertices of the box (relative to the origin), structured like the file NOTEBOOKS/boxes_example.yml.\n",
    "\n",
    "2-Alternatively, use a software called FreeCAD to define the volumes, save them in STEP format, generate meshes, and then convert them into .yml files via a terminal command (you can find this command in NOTEBOOKS/STEP_TO_YML.py).\n",
    "\n",
    "If the boxes folder doesn’t exist in the data directory, create it using the next step. Then, place the newly created boxes.yml file inside it.\n",
    "Important! The file must be named boxes.yml!\n",
    "\n",
    "To verify the correct structure, you can use the viewboxes function..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec488eba-f1fd-4edf-8866-45f6b2680b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "os.makedirs('EasyMocap/data/boxes', exist_ok=True)\n",
    "shutil.copy('EasyMocap/yamls/REORIENTED/extri.yml','EasyMocap/data/boxes/')\n",
    "shutil.copy('EasyMocap/yamls/REORIENTED/intri.yml','EasyMocap/data/boxes/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893d42af-f209-4ea8-9260-37c6127621a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python EasyMocap/apps/hopeitworks/viewboxes.py EasyMocap/data/boxes/boxes.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b4691d-e854-47a6-a1df-0a7479b315cc",
   "metadata": {},
   "source": [
    "To project the boxes into our real-world system (video frames) to verify if the bounding boxes align with reality, we can use the following code cell. The results can be viewed in: EasyMocap/data/boxes/boxes/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0566ab-a0da-46f6-8642-03c6e2e6144c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python EasyMocap/apps/hopeitworks/boxesprojection.py EasyMocap/data --out EasyMocap/data/boxes/ --boxes-yml EasyMocap/data/boxes/boxes.yml --write"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3e514e-aa86-4102-a0e5-ab65ac1b44dc",
   "metadata": {},
   "source": [
    "Now, with the next cell, we’ll clean the previously used 'data' folder (employed for motion capture of keypoints to define O-X-Y, if populated) and proceed with:\n",
    "\n",
    "1-Loading new videos into data/videos.\n",
    "\n",
    "2-Detecting keypoints as shown in Tutorial 3...\n",
    "\n",
    "These videos capture the operator performing activities on the various components of the product in question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e586a4-a213-4782-a287-cee458f23569",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "!python EasyMocap/apps/hopeitworks/cleanhandmocap.py\n",
    "os.remove('EasyMocap/data/extri.yml')  \n",
    "os.remove('EasyMocap/data/intri.yml')  \n",
    "shutil.copy('EasyMocap/yamls/REORIENTED/extri.yml','EasyMocap/data/')\n",
    "shutil.copy('EasyMocap/yamls/REORIENTED/intri.yml','EasyMocap/data/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef50bdf3-8535-4d1f-be3f-4b121c35b700",
   "metadata": {},
   "source": [
    "With the next cell (warning: it will take a while), we repeat the steps already seen in Tutorial 3: images → to annots → to kp3d."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beddc3ff-cc43-41fc-91c3-68288559f9d3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "##ESTRAE IMMAGINI DA VIDEO\n",
    "import time\n",
    "import os\n",
    "# Inizio del timer\n",
    "start_time = time.time()\n",
    "\n",
    "# ESTRAZIONE IMMAGINI\n",
    "!python EasyMocap/apps/preprocess/extract_image.py EasyMocap/data\n",
    "\n",
    "# Fine del timer\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "# Salva il tempo in un file txt\n",
    "with open('EasyMocap/data/times.txt', 'a') as f:\n",
    "    f.write(f't extract_image, {elapsed_time:.2f}\\n')\n",
    "##ESTRAE KEYPOINTS\n",
    "import time\n",
    "import os\n",
    "import json\n",
    "import shutil\n",
    "# Inizio del timer\n",
    "start_time = time.time()\n",
    "\n",
    "## MANO SINISTRA\n",
    "!python EasyMocap/apps/preprocess/extract_keypoints.py EasyMocap/data --mode mp-handl\n",
    "## RINOMINA ANNOTS IN ANNOTSL PER CONVENIENZA DEL SUCCESSIVO ANNOT (DELLA MANO DESTRA)\n",
    "os.rename('EasyMocap/data/annots', 'EasyMocap/data/annotsl')\n",
    "## MANO DESTRA\n",
    "!python EasyMocap/apps/preprocess/extract_keypoints.py EasyMocap/data --mode mp-handr\n",
    "\n",
    "\n",
    "##INIZIO JOIN DELLE DUE CARTELLE ANNOTS\n",
    "\n",
    "# Define the path to your main folder\n",
    "main_folder_path = 'EasyMocap/data/annotsl'\n",
    "\n",
    "# Get a list of sub-folders within the main folder\n",
    "subfolders = [f.path for f in os.scandir(main_folder_path)]\n",
    "\n",
    "# Loop through each sub-folder\n",
    "for subfolder_path in subfolders:\n",
    "\n",
    "    # Get a list of JSON files within the sub-folder\n",
    "    json_files = [f.path for f in os.scandir(subfolder_path)]\n",
    "\n",
    "    # Loop through the JSON files in the sub-folder\n",
    "    for json_file_path in json_files:\n",
    "\n",
    "        # You can now read and process the JSON file\n",
    "        with open(json_file_path, 'r') as json_file:\n",
    "            data = json.load(json_file)\n",
    "            json_file_path_dest = json_file_path.replace(\"annotsl\", \"annots\")\n",
    "\n",
    "            # Step 1: Read the existing data from the destination JSON file\n",
    "            with open(json_file_path_dest, 'r') as json_file:\n",
    "                existing_data = json.load(json_file)\n",
    "\n",
    "            # Step 2: Modify or add new data to the existing data\n",
    "            existing_data[\"annots\"][0][\"handl2d\"] =  data[\"annots\"][0][\"handl2d\"]\n",
    "            existing_data[\"annots\"][0][\"bbox_handl2d\"] =  data[\"annots\"][0][\"bbox_handl2d\"]\n",
    "\n",
    "            # Step 3: Write the updated data back to the JSON file\n",
    "            with open(json_file_path_dest, 'w') as json_file:\n",
    "                json.dump(existing_data, json_file, indent=4)\n",
    "\n",
    "shutil.rmtree('EasyMocap/data/annotsl')\n",
    "##FINE JOIN DELLE DUE CARTELLE ANNOTS\n",
    "\n",
    "# Fine del timer\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "# Salva il tempo in un file txt\n",
    "with open('EasyMocap/data/times.txt', 'a') as f:\n",
    "    f.write(f't extract_keypoints, {elapsed_time:.2f}\\n')\n",
    "\n",
    "##in times.txt, SCRIVERE A INIZIO FILE NUMERO FRAME E NUMERO FPS CON QUESTO FORMATO EX. (#FRAMES, 434 /n #FPS, 9)\n",
    "##TRIANGOLAZIONE K2D->K3D\n",
    "import time\n",
    "\n",
    "# Inizio del timer\n",
    "start_time = time.time()\n",
    "\n",
    "!python EasyMocap/apps/fit/triangulate1p.py --cfg_data EasyMocap/config/recon/mv1p.yml --opt_data args.path EasyMocap/data args.out EasyMocap/data/output-keypoints3d --cfg_exp EasyMocap/config/recon/triangulator-mv1p-total.yml --opt_exp  args.debug True\n",
    "\n",
    "# Fine del timer\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "# Salva il tempo in un file txt\n",
    "with open('EasyMocap/data/times.txt', 'a') as f:\n",
    "    f.write(f't triangulate, {elapsed_time:.2f}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148d5331-659f-4739-a641-ad93cac2c9ec",
   "metadata": {},
   "source": [
    "**ITERATIVE STEP** \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2132bd68-e861-45a0-a05e-0a3870250c61",
   "metadata": {},
   "source": [
    "Now we proceed with detecting whether the keypoints and bounding boxes come into contact and intersect using the following function:\n",
    "\n",
    "P.S. If this isn't your first time here (you've already completed the steps below), activate and run cleanboxes, where we'll clean the 'boxes' folder from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657bc18b-75e0-45c0-8c2d-843f7a467e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python EasyMocap/apps/hopeitworks/cleanboxes.py \n",
    "\n",
    "!python EasyMocap/apps/hopeitworks/rilevak3d.py EasyMocap/data/boxes/boxes.yml EasyMocap/data/output-keypoints3d/keypoints3d EasyMocap/data/boxes/results.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729acc22-958f-43e6-ba5a-bbbda4767957",
   "metadata": {},
   "source": [
    "And with the creation of the images (this time with the boxes changing color):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f850b7a5-d8d0-44ea-b6c7-919246147a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python EasyMocap/apps/hopeitworks/boxesprojection.py EasyMocap/data --out EasyMocap/data/boxes/ --boxes-yml EasyMocap/data/boxes/boxes.yml --results EasyMocap/data/boxes/results.csv --write"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1386c0-1013-48c8-b36c-91df092ebe76",
   "metadata": {},
   "source": [
    "The following cell will allow us to create a video where we can see our results.\n",
    "WARNING!! REPLACE CAM1, CAM2, CAM3, ETC. with the names of the cameras (from the original videos).\n",
    "\n",
    "You will find the videos in the path → EasyMocap/data/boxes/boxes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91a93b4-a46a-4358-9a40-56cd3ae5de61",
   "metadata": {},
   "outputs": [],
   "source": [
    "##CREA VIDEO\n",
    "import cv2\n",
    "video = cv2.VideoCapture(\"EasyMocap/data/videos/CAM1.mp4\");\n",
    "fps = video.get(cv2.CAP_PROP_FPS)\n",
    "print(\"Frames per second using video.get(cv2.CAP_PROP_FPS) : {0}\".format(fps))\n",
    "fps = int(fps)\n",
    "\n",
    "!python -m easymocap.visualize.ffmpeg_wrapper EasyMocap/data/boxes/boxes/CAM1 --fps $fps\n",
    "!python -m easymocap.visualize.ffmpeg_wrapper EasyMocap/data/boxes/boxes/CAM2 --fps $fps\n",
    "!python -m easymocap.visualize.ffmpeg_wrapper EasyMocap/data/boxes/boxes/CAM3 --fps $fps\n",
    "!python -m easymocap.visualize.ffmpeg_wrapper EasyMocap/data/boxes/boxes/CAM4 --fps $fps\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620b3dfb-41e4-4fd2-b9b1-bfaee702bc76",
   "metadata": {},
   "source": [
    "Once the videos are analyzed, you can choose whether to be satisfied with the results or modify the geometries of the bounding boxes using the tool provided below (TO BE RUN IN THE TERMINAL!) and repeat the process starting again from the ITERATIVE STEP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f4100b-2c37-4355-b940-e96cdc74a05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#python EasyMocap/apps/hopeitworks/boxestool.py EasyMocap/data/boxes/boxes.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff224f7-026e-4f9d-a5ac-6744304e564b",
   "metadata": {},
   "source": [
    "AU REVOIR!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
